{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import utils\n",
    "import pickle\n",
    "from utils import MetricLogger\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import torchvision\n",
    "from torchvision.utils import draw_bounding_boxes\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor\n",
    "from torchvision.models.detection import maskrcnn_resnet50_fpn, MaskRCNN_ResNet50_FPN_Weights\n",
    "import torch.utils.data\n",
    "import transforms as T\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageOps\n",
    "from engine import train_one_epoch, evaluate\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### define dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, image_path, body_path, transform=True):\n",
    "        self.transform = transform\n",
    "        # load data\n",
    "        self.filenames = [path for path in sorted(os.listdir(image_path))]\n",
    "        self.image_paths = [os.path.join(image_path, path) for path in sorted(os.listdir(image_path))]\n",
    "        self.body_paths = [os.path.join(body_path, path) for path in sorted(os.listdir(body_path))]\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        # load filename\n",
    "        filename = self.filenames[idx]\n",
    "        \n",
    "        # load images and masks\n",
    "        image = cv2.cvtColor(cv2.imread(self.image_paths[idx]), cv2.COLOR_BGR2RGB)\n",
    "        body = cv2.imread(self.body_paths[idx])\n",
    "        skin = cv2.cvtColor(body, cv2.COLOR_RGB2GRAY)\n",
    "        \n",
    "        # save image copy\n",
    "        image_no_mask = image.copy()\n",
    "        \n",
    "        # apply body mask\n",
    "        image = Image.fromarray(image*body)\n",
    "\n",
    "        target = {}\n",
    "\n",
    "        if self.transform:\n",
    "            image, target = T.ToTensor()(image, target)\n",
    "\n",
    "        return image, image_no_mask, filename\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_instance_segmentation_model(num_classes):\n",
    "    # load an instance segmentation model pre-trained on COCO\n",
    "    model = maskrcnn_resnet50_fpn(weights=MaskRCNN_ResNet50_FPN_Weights.DEFAULT)\n",
    "\n",
    "    # get the number of input features for the classifier\n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "    # replace the pre-trained head with a new one\n",
    "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "\n",
    "    # now get the number of input features for the mask classifier\n",
    "    in_features_mask = model.roi_heads.mask_predictor.conv5_mask.in_channels\n",
    "    hidden_layer = 256\n",
    "    # and replace the mask predictor with a new one\n",
    "    model.roi_heads.mask_predictor = MaskRCNNPredictor(in_features_mask, hidden_layer, num_classes)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = os.path.join(\"..\")\n",
    "data_path = os.path.join(base_path, \"data\")\n",
    "model_path = os.path.join(base_path, \"model\")\n",
    "checkpoint_file = \"MRCNN.pth.tar\"\n",
    "\n",
    "input_path = os.path.join(data_path, \"joint-ep-of-thu-ego-heiko\", \"train\")\n",
    "image_path = os.path.join(input_path, \"images\")\n",
    "body_path = os.path.join(input_path, \"labels\")\n",
    "\n",
    "batch_size = 8\n",
    "num_workers = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlay_two_images(image, overlay, ignore_color=[0,0,0]):\n",
    "    ignore_color = np.asarray(ignore_color)\n",
    "    mask = (overlay==ignore_color).all(-1, keepdims=True)\n",
    "    out = np.where(mask,image,(image * 0.5 + overlay * 0.5).astype(image.dtype))\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c7d7c15d03a48fc8f4eb34132a6f341",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1001 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# dataset\n",
    "dataset = Dataset(image_path=image_path, body_path=body_path)\n",
    "torch.manual_seed(1)\n",
    "data_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers, collate_fn=utils.collate_fn)\n",
    "\n",
    "# target folders\n",
    "mask_save_path = os.path.join(input_path, \"preds\")\n",
    "overlay_save_path = os.path.join(input_path, \"overlays\")\n",
    "os.makedirs(mask_save_path, exist_ok=True)\n",
    "os.makedirs(overlay_save_path, exist_ok=True)\n",
    "\n",
    "# run\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "for epoch in [5]:\n",
    "    print(\"epoch: \", epoch)\n",
    "\n",
    "    # load model\n",
    "    checkpoint_path = os.path.join(model_path, f\"{epoch}_{checkpoint_file}\")\n",
    "    num_classes= 2\n",
    "    CLASS_NAMES = ['__background__', 'skin']\n",
    "\n",
    "    model = get_instance_segmentation_model(num_classes)\n",
    "    model.to(device)\n",
    "    model.load_state_dict(torch.load(checkpoint_path, map_location=device))\n",
    "    model.eval()\n",
    "\n",
    "    # predict\n",
    "    with torch.no_grad():\n",
    "        pbar = tqdm(data_loader)\n",
    "        for i, (images, images_no_mask, filenames) in enumerate(pbar):\n",
    "            images = [image.to(device) for image in images]\n",
    "            predictions = model(images)\n",
    "            for j, (image_no_mask, pred, filename) in enumerate(zip(images_no_mask, predictions, filenames)):\n",
    "                filename = filename.replace(\".jpg\", \".png\")\n",
    "                                \n",
    "                # merge pred\n",
    "                pred_masks = (pred[\"masks\"]).squeeze(dim=1).detach().cpu().numpy()\n",
    "                merged_pred_mask = np.zeros(image_no_mask.shape[:2], dtype=np.uint8)\n",
    "                for mask in pred_masks:\n",
    "                    merged_pred_mask[mask > 0.5] = 1\n",
    "                \n",
    "                # create overlay\n",
    "                mask = cv2.merge([merged_pred_mask*0, merged_pred_mask*255, merged_pred_mask*0]).astype(\"uint8\")     \n",
    "                overlay = overlay_two_images(image_no_mask, mask)\n",
    "                \n",
    "                # save\n",
    "                cv2.imwrite(os.path.join(mask_save_path, filename), merged_pred_mask)\n",
    "                cv2.imwrite(os.path.join(overlay_save_path, filename), overlay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
